{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3a179c",
   "metadata": {},
   "source": [
    "# Python Data Structures Learning - 10 Code Questions & Solutions\n",
    "\n",
    "Master Python data structures with practical coding exercises covering lists, tuples, dictionaries, sets, and advanced techniques using collections and heapq modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be901590",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports\n",
    "\n",
    "Import standard libraries and define a helper function for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "063f3230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, deque, OrderedDict, defaultdict\n",
    "from dataclasses import dataclass\n",
    "import heapq\n",
    "\n",
    "def assert_test(condition, message=\"Test failed\"):\n",
    "    \"\"\"Helper function for quick assertions\"\"\"\n",
    "    assert condition, message\n",
    "    print(f\"✓ {message}\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Common helpers used by multiple questions (linked lists etc.)\n",
    "class Node:\n",
    "    def __init__(self, val, nxt=None):\n",
    "        self.val = val\n",
    "        self.next = nxt\n",
    "\n",
    "def list_from_vals(vals):\n",
    "    head = None\n",
    "    for v in reversed(vals):\n",
    "        head = Node(v, head)\n",
    "    return head\n",
    "\n",
    "def vals_from_list(head):\n",
    "    out = []\n",
    "    while head:\n",
    "        out.append(head.val)\n",
    "        head = head.next\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288bef0a",
   "metadata": {},
   "source": [
    "## Q1: Remove Duplicates from a List While Preserving Order\n",
    "\n",
    "**Problem:** Implement a function `unique_preserve_order(lst)` that returns a list with duplicate elements removed while maintaining the original order of first occurrence.\n",
    "\n",
    "**Hint:** Use a set to track seen items.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "unique_preserve_order([1, 2, 2, 3, 1, 4]) → [1, 2, 3, 4]\n",
    "unique_preserve_order(['a', 'b', 'a', 'c']) → ['a', 'b', 'c']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776aad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [1, 2, 2, 3, 1, 4] -> Output: [1, 2, 3, 4]\n",
      "✓ Q1: Remove duplicates from [1, 2, 2, 3, 1, 4]\n",
      "Input: ['a', 'b', 'a', 'c'] -> Output: ['a', 'b', 'c']\n",
      "✓ Q1: Remove duplicates from strings\n",
      "Input: [] -> Output: []\n",
      "✓ Q1: Handle empty list\n",
      "Input: [1, 1, 1] -> Output: [1]\n",
      "✓ Q1: All duplicates\n"
     ]
    }
   ],
   "source": [
    "# Q1 Solution: Remove Duplicates While Preserving Order\n",
    "\n",
    "def unique_preserve_order(lst):\n",
    "    \"\"\"Remove duplicates from list while preserving order of first occurrence\"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in lst:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            result.append(item)\n",
    "    print(f\"Input: {lst} -> Output: {result}\")\n",
    "    return result\n",
    "    \n",
    "\n",
    "# Test cases\n",
    "assert_test(\n",
    "    unique_preserve_order([1, 2, 2, 3, 1, 4]) == [1, 2, 3, 4],\n",
    "    \"Q1: Remove duplicates from [1, 2, 2, 3, 1, 4]\"\n",
    ")\n",
    "\n",
    "assert_test(\n",
    "    unique_preserve_order(['a', 'b', 'a', 'c']) == ['a', 'b', 'c'],\n",
    "    \"Q1: Remove duplicates from strings\"\n",
    ")\n",
    "\n",
    "assert_test(\n",
    "    unique_preserve_order([]) == [],\n",
    "    \"Q1: Handle empty list\"\n",
    ")\n",
    "\n",
    "assert_test(\n",
    "    unique_preserve_order([1, 1, 1]) == [1],\n",
    "    \"Q1: All duplicates\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b956e",
   "metadata": {},
   "source": [
    "## Q2: Swap Two Variables Using Tuple Unpacking\n",
    "\n",
    "**Problem:** Implement a function `swap(a, b)` that swaps the values of two variables using tuple unpacking without using a temporary variable.\n",
    "\n",
    "**Hint:** Tuples allow elegant swapping via unpacking.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "swap(5, 10) → (10, 5)\n",
    "swap('hello', 'world') → ('world', 'hello')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0721a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Solution: Swap Two Variables Using Tuple Unpacking\n",
    "\n",
    "def swap(a, b):\n",
    "    \"\"\"Swap two values using tuple unpacking\"\"\"\n",
    "    return (b, a)\n",
    "\n",
    "# Test cases\n",
    "a, b = swap(5, 10)\n",
    "assert_test(a == 10 and b == 5, \"Q2: Swap integers\")\n",
    "\n",
    "s1, s2 = swap('hello', 'world')\n",
    "assert_test(s1 == 'world' and s2 == 'hello', \"Q2: Swap strings\")\n",
    "\n",
    "lst1, lst2 = swap([1, 2], [3, 4])\n",
    "assert_test(lst1 == [3, 4] and lst2 == [1, 2], \"Q2: Swap lists\")\n",
    "\n",
    "x, y = swap(True, False)\n",
    "assert_test(x == False and y == True, \"Q2: Swap booleans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b49a3",
   "metadata": {},
   "source": [
    "## Q3: Invert a Dictionary - Map Values to Lists of Keys\n",
    "\n",
    "**Problem:** Implement a function `invert_dict(d)` that takes a dictionary and returns a new dictionary where each original value maps to a list of keys that had that value. Preserve insertion order of keys for each value.\n",
    "\n",
    "**Hint:** Use `defaultdict(list)` from the collections module.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "invert_dict({'a': 1, 'b': 2, 'c': 1}) → {1: ['a', 'c'], 2: ['b']}\n",
    "invert_dict({'x': 'color', 'y': 'color'}) → {'color': ['x', 'y']}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Solution: Invert Dictionary - Map Values to Lists of Keys\n",
    "\n",
    "def invert_dict(d):\n",
    "    \"\"\"Invert a dictionary to map values to lists of keys\"\"\"\n",
    "    result = defaultdict(list)\n",
    "    for key, value in d.items():\n",
    "        result[value].append(key)\n",
    "    return dict(result)\n",
    "\n",
    "# Test cases\n",
    "result1 = invert_dict({'a': 1, 'b': 2, 'c': 1})\n",
    "assert_test(\n",
    "    result1 == {1: ['a', 'c'], 2: ['b']},\n",
    "    \"Q3: Invert dictionary with duplicate values\"\n",
    ")\n",
    "\n",
    "result2 = invert_dict({'x': 'color', 'y': 'color', 'z': 'size'})\n",
    "assert_test(\n",
    "    result2 == {'color': ['x', 'y'], 'size': ['z']},\n",
    "    \"Q3: Invert dictionary with strings\"\n",
    ")\n",
    "\n",
    "result3 = invert_dict({})\n",
    "assert_test(result3 == {}, \"Q3: Handle empty dictionary\")\n",
    "\n",
    "result4 = invert_dict({'a': 1, 'b': 1, 'c': 1})\n",
    "assert_test(\n",
    "    result4 == {1: ['a', 'b', 'c']},\n",
    "    \"Q3: All keys map to same value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c3cbc",
   "metadata": {},
   "source": [
    "## Q4: Intersection of Multiple Sets\n",
    "\n",
    "**Problem:** Implement a function `intersection_of_sets(sets)` that returns the intersection of an iterable of sets (elements common to all sets). Handle empty input by returning an empty set.\n",
    "\n",
    "**Hint:** Use the `intersection()` method and handle the edge case of no sets.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "intersection_of_sets([{1, 2, 3}, {2, 3, 4}, {2, 3, 5}]) → {2, 3}\n",
    "intersection_of_sets([]) → set()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af1a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4 Solution: Intersection of Multiple Sets\n",
    "\n",
    "def intersection_of_sets(sets):\n",
    "    \"\"\"Return the intersection of an iterable of sets\"\"\"\n",
    "    sets_list = list(sets)\n",
    "    if not sets_list:\n",
    "        return set()\n",
    "    return sets_list[0].intersection(*sets_list[1:])\n",
    "\n",
    "# Alternative solution using reduce (more elegant)\n",
    "# def intersection_of_sets(sets):\n",
    "#     from functools import reduce\n",
    "#     sets_list = list(sets)\n",
    "#     if not sets_list:\n",
    "#         return set()\n",
    "#     return reduce(lambda a, b: a.intersection(b), sets_list)\n",
    "\n",
    "# Test cases\n",
    "result1 = intersection_of_sets([{1, 2, 3}, {2, 3, 4}, {2, 3, 5}])\n",
    "assert_test(result1 == {2, 3}, \"Q4: Intersection of three sets\")\n",
    "\n",
    "result2 = intersection_of_sets([{1, 2, 3}, {1, 2, 3}, {1, 2, 3}])\n",
    "assert_test(result2 == {1, 2, 3}, \"Q4: Identical sets\")\n",
    "\n",
    "result3 = intersection_of_sets([])\n",
    "assert_test(result3 == set(), \"Q4: Empty input\")\n",
    "\n",
    "result4 = intersection_of_sets([{1, 2}, {3, 4}])\n",
    "assert_test(result4 == set(), \"Q4: No common elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a01add",
   "metadata": {},
   "source": [
    "## Q5: Flatten a Nested List (2 Levels) with List Comprehension\n",
    "\n",
    "**Problem:** Implement a function `flatten_2levels(nested)` that flattens a list of lists into a single list using a list comprehension.\n",
    "\n",
    "**Hint:** Use nested loops in list comprehension: `[item for sublist in nested for item in sublist]`\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "flatten_2levels([[1, 2], [3, 4], [5, 6]]) → [1, 2, 3, 4, 5, 6]\n",
    "flatten_2levels([['a'], ['b', 'c'], []]) → ['a', 'b', 'c']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5 Solution: Flatten a Nested List with List Comprehension\n",
    "\n",
    "def flatten_2levels(nested):\n",
    "    \"\"\"Flatten a 2-level nested list using list comprehension\"\"\"\n",
    "    return [item for sublist in nested for item in sublist]\n",
    "\n",
    "# Test cases\n",
    "result1 = flatten_2levels([[1, 2], [3, 4], [5, 6]])\n",
    "assert_test(\n",
    "    result1 == [1, 2, 3, 4, 5, 6],\n",
    "    \"Q5: Flatten list of lists with numbers\"\n",
    ")\n",
    "\n",
    "result2 = flatten_2levels([['a'], ['b', 'c'], []])\n",
    "assert_test(\n",
    "    result2 == ['a', 'b', 'c'],\n",
    "    \"Q5: Flatten with empty sublists\"\n",
    ")\n",
    "\n",
    "result3 = flatten_2levels([])\n",
    "assert_test(result3 == [], \"Q5: Empty nested list\")\n",
    "\n",
    "result4 = flatten_2levels([[], [], [1, 2, 3]])\n",
    "assert_test(result4 == [1, 2, 3], \"Q5: Multiple empty sublists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b439e",
   "metadata": {},
   "source": [
    "## Q6: Count Element Frequencies with collections.Counter\n",
    "\n",
    "**Problem:** Implement a function `top_n_frequencies(seq, n)` that returns a list of the top-n most common elements with their counts as tuples using `Counter.most_common()`.\n",
    "\n",
    "**Hint:** Use `Counter(seq).most_common(n)` to get top-n elements.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "top_n_frequencies([1, 1, 1, 2, 2, 3], 2) → [(1, 3), (2, 2)]\n",
    "top_n_frequencies('aabbcc', 2) → [('a', 2), ('b', 2)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6 Solution: Count Element Frequencies with Counter\n",
    "\n",
    "def top_n_frequencies(seq, n):\n",
    "    \"\"\"Return top-n most common elements with their frequencies\"\"\"\n",
    "    return Counter(seq).most_common(n)\n",
    "\n",
    "# Test cases\n",
    "result1 = top_n_frequencies([1, 1, 1, 2, 2, 3], 2)\n",
    "assert_test(\n",
    "    result1 == [(1, 3), (2, 2)],\n",
    "    \"Q6: Top 2 frequencies from list\"\n",
    ")\n",
    "\n",
    "result2 = top_n_frequencies('aabbccdddd', 2)\n",
    "assert_test(\n",
    "    result2[0] == ('d', 4) and result2[1][0] in ['a', 'b', 'c'],\n",
    "    \"Q6: Top 2 frequencies from string\"\n",
    ")\n",
    "\n",
    "result3 = top_n_frequencies([1, 2, 3, 4, 5], 3)\n",
    "assert_test(\n",
    "    len(result3) == 3,\n",
    "    \"Q6: Top 3 from list with equal frequencies\"\n",
    ")\n",
    "\n",
    "result4 = top_n_frequencies([1], 5)\n",
    "assert_test(\n",
    "    result4 == [(1, 1)],\n",
    "    \"Q6: n larger than unique elements\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e2ce08",
   "metadata": {},
   "source": [
    "## Q7: Simple LRU Cache Using collections.OrderedDict\n",
    "\n",
    "**Problem:** Implement a simple `LRUCache` class with methods `get(key)` and `put(key, value)` and a fixed capacity. When the cache reaches capacity, evict the least recently used (oldest) item. Use `OrderedDict` to track insertion order.\n",
    "\n",
    "**Hint:** Use `OrderedDict.move_to_end()` to mark recent access and `popitem(last=False)` to remove oldest.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "cache = LRUCache(2)\n",
    "cache.put('a', 1)\n",
    "cache.put('b', 2)\n",
    "cache.get('a')  # returns 1, moves 'a' to end\n",
    "cache.put('c', 3)  # evicts 'b' (oldest)\n",
    "cache.get('b')  # returns -1 (not found)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895dcf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7 Solution: Simple LRU Cache Using OrderedDict\n",
    "\n",
    "class LRUCache:\n",
    "    \"\"\"LRU Cache implementation using OrderedDict\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.cache = OrderedDict()\n",
    "        self.capacity = capacity\n",
    "    \n",
    "    def get(self, key):\n",
    "        \"\"\"Get value and mark as recently used, return -1 if not found\"\"\"\n",
    "        if key not in self.cache:\n",
    "            return -1\n",
    "        # Move to end to mark as recently used\n",
    "        self.cache.move_to_end(key)\n",
    "        return self.cache[key]\n",
    "    \n",
    "    def put(self, key, value):\n",
    "        \"\"\"Put key-value pair, evicting oldest if at capacity\"\"\"\n",
    "        if key in self.cache:\n",
    "            # Update value and move to end\n",
    "            self.cache[key] = value\n",
    "            self.cache.move_to_end(key)\n",
    "        else:\n",
    "            # Add new item\n",
    "            self.cache[key] = value\n",
    "            if len(self.cache) > self.capacity:\n",
    "                # Remove oldest (first) item\n",
    "                self.cache.popitem(last=False)\n",
    "\n",
    "# Test cases\n",
    "cache = LRUCache(2)\n",
    "cache.put('a', 1)\n",
    "cache.put('b', 2)\n",
    "assert_test(cache.get('a') == 1, \"Q7: Get existing key 'a'\")\n",
    "\n",
    "cache.put('c', 3)  # Should evict 'b' (oldest)\n",
    "assert_test(cache.get('b') == -1, \"Q7: 'b' should be evicted\")\n",
    "assert_test(cache.get('a') == 1, \"Q7: 'a' should still exist\")\n",
    "\n",
    "cache.put('d', 4)  # Should evict 'c'\n",
    "assert_test(cache.get('c') == -1, \"Q7: 'c' should be evicted\")\n",
    "assert_test(cache.get('d') == 4, \"Q7: 'd' should exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b947f",
   "metadata": {},
   "source": [
    "## Q8: Convert List of Tuples to Dataclass Instances and Filter\n",
    "\n",
    "**Problem:** Define a dataclass `Item(name: str, price: float, qty: int)`. Implement `tuples_to_items(data)` that converts a list of tuples to Item instances, and `filter_by_price(items, min_price)` that returns items with price >= min_price.\n",
    "\n",
    "**Hint:** Use `@dataclass` decorator from the dataclasses module.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "data = [('apple', 1.5, 10), ('banana', 0.5, 20)]\n",
    "items = tuples_to_items(data)\n",
    "filtered = filter_by_price(items, 1.0)  # → [Item('apple', 1.5, 10)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51377d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8 Solution: Convert Tuples to Dataclass Instances and Filter\n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    \"\"\"Represents an item with name, price, and quantity\"\"\"\n",
    "    name: str\n",
    "    price: float\n",
    "    qty: int\n",
    "\n",
    "def tuples_to_items(data):\n",
    "    \"\"\"Convert list of tuples to Item dataclass instances\"\"\"\n",
    "    return [Item(name, price, qty) for name, price, qty in data]\n",
    "\n",
    "def filter_by_price(items, min_price):\n",
    "    \"\"\"Filter items by minimum price\"\"\"\n",
    "    return [item for item in items if item.price >= min_price]\n",
    "\n",
    "# Test cases\n",
    "data = [('apple', 1.5, 10), ('banana', 0.5, 20), ('orange', 2.0, 5)]\n",
    "items = tuples_to_items(data)\n",
    "\n",
    "assert_test(\n",
    "    len(items) == 3 and items[0].name == 'apple',\n",
    "    \"Q8: Convert tuples to Item instances\"\n",
    ")\n",
    "\n",
    "filtered = filter_by_price(items, 1.0)\n",
    "assert_test(\n",
    "    len(filtered) == 2 and filtered[0].name == 'apple',\n",
    "    \"Q8: Filter items by minimum price\"\n",
    ")\n",
    "\n",
    "filtered2 = filter_by_price(items, 3.0)\n",
    "assert_test(\n",
    "    len(filtered2) == 0,\n",
    "    \"Q8: No items meet minimum price\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c7c79",
   "metadata": {},
   "source": [
    "## Q9: Find k Largest Elements with heapq\n",
    "\n",
    "**Problem:** Implement a function `k_largest(iterable, k)` that returns a list of the k largest elements using `heapq.nlargest()`.\n",
    "\n",
    "**Hint:** Use `heapq.nlargest(k, iterable)` to efficiently get the k largest elements.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "k_largest([1, 5, 3, 9, 2, 8], 3) → [9, 8, 5]\n",
    "k_largest([-1, -5, -3, -2], 2) → [-1, -2]\n",
    "k_largest([1], 5) → [1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473edd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9 Solution: Find k Largest Elements with heapq\n",
    "\n",
    "def k_largest(iterable, k):\n",
    "    \"\"\"Return a list of k largest elements\"\"\"\n",
    "    return heapq.nlargest(k, iterable)\n",
    "\n",
    "# Test cases\n",
    "result1 = k_largest([1, 5, 3, 9, 2, 8], 3)\n",
    "assert_test(\n",
    "    result1 == [9, 8, 5],\n",
    "    \"Q9: Find 3 largest from mixed list\"\n",
    ")\n",
    "\n",
    "result2 = k_largest([-1, -5, -3, -2], 2)\n",
    "assert_test(\n",
    "    result2 == [-1, -2],\n",
    "    \"Q9: Find 2 largest from negative numbers\"\n",
    ")\n",
    "\n",
    "result3 = k_largest([1], 5)\n",
    "assert_test(\n",
    "    result3 == [1],\n",
    "    \"Q9: k larger than list size\"\n",
    ")\n",
    "\n",
    "result4 = k_largest([5, 5, 5, 1, 1], 2)\n",
    "assert_test(\n",
    "    result4 == [5, 5],\n",
    "    \"Q9: Handle duplicate largest values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f26057",
   "metadata": {},
   "source": [
    "## Q10: Sliding-Window Maximum Using collections.deque\n",
    "\n",
    "**Problem:** Implement a function `sliding_max(nums, k)` that returns a list of the maximum value in each sliding window of size k using a monotonic deque. Maintain indices in deque to track valid window elements.\n",
    "\n",
    "**Hint:** Use `deque` to store indices in decreasing order of their values. Remove indices outside the window and non-maximal values.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "sliding_max([1, 3, 1, 2, 0, 5], 3) → [3, 3, 2, 5]\n",
    "sliding_max([1], 1) → [1]\n",
    "sliding_max([1, 2, 3], 5) → []\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040751fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10 Solution: Sliding-Window Maximum Using deque (indices)\n",
    "def sliding_max(nums, k):\n",
    "    \"\"\"Return max of each sliding window of size k using a monotonic deque of indices\"\"\"\n",
    "    if k <= 0 or not nums or k > len(nums):\n",
    "        return []\n",
    "    dq = deque()  # stores indices, values decreasing\n",
    "    res = []\n",
    "    for i, n in enumerate(nums):\n",
    "        # remove indices outside the window\n",
    "        while dq and dq[0] <= i - k:\n",
    "            dq.popleft()\n",
    "        # remove smaller values from right\n",
    "        while dq and nums[dq[-1]] < n:\n",
    "            dq.pop()\n",
    "        dq.append(i)\n",
    "        if i >= k - 1:\n",
    "            res.append(nums[dq[0]])\n",
    "    return res\n",
    "\n",
    "# Tests\n",
    "assert_test(sliding_max([1, 3, 1, 2, 0, 5], 3) == [3, 3, 2, 5], \"Q10: Example 1\")\n",
    "assert_test(sliding_max([1], 1) == [1], \"Q10: Single element\")\n",
    "assert_test(sliding_max([1, 2, 3], 5) == [], \"Q10: k > len(nums) returns []\")\n",
    "assert_test(sliding_max([], 3) == [], \"Q10: empty list\")\n",
    "assert_test(sliding_max([9, 8, 7, 6], 2) == [9, 8, 7], \"Q10: strictly decreasing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6b125",
   "metadata": {},
   "source": [
    "## Additional Problems (Q11–Q30): Data Structures with Solutions\n",
    "\n",
    "Below are 20 additional practical data-structure problems with concise implementations and tests. Each problem has a short description and a working Python solution using the helpers defined earlier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155fe60",
   "metadata": {},
   "source": [
    "### Q11: Reverse a Singly Linked List (Iterative)\n",
    "\n",
    "Problem: Reverse a singly linked list in-place and return new head.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3287258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11 Solution\n",
    "class Node:\n",
    "    def __init__(self, val, nxt=None):\n",
    "        self.val = val\n",
    "        self.next = nxt\n",
    "\n",
    "def reverse_list(head):\n",
    "    prev = None\n",
    "    cur = head\n",
    "    while cur:\n",
    "        nxt = cur.next\n",
    "        cur.next = prev\n",
    "        prev = cur\n",
    "        cur = nxt\n",
    "    return prev\n",
    "\n",
    "# Helper to build and read list\n",
    "def list_from_vals(vals):\n",
    "    head = None\n",
    "    for v in reversed(vals):\n",
    "        head = Node(v, head)\n",
    "    return head\n",
    "\n",
    "def vals_from_list(head):\n",
    "    out = []\n",
    "    while head:\n",
    "        out.append(head.val)\n",
    "        head = head.next\n",
    "    return out\n",
    "\n",
    "h = list_from_vals([1,2,3,4])\n",
    "rh = reverse_list(h)\n",
    "assert_test(vals_from_list(rh) == [4,3,2,1], \"Q11: Reverse linked list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74362772",
   "metadata": {},
   "source": [
    "### Q12: Stack with O(1) min() Operation\n",
    "\n",
    "Problem: Implement a stack supporting push, pop, top, and min in constant time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae3e881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Q12: min after pushes\n",
      "✓ Q12: min after pops\n"
     ]
    }
   ],
   "source": [
    "# Q12 Solution\n",
    "class MinStack:\n",
    "    def __init__(self):\n",
    "        self.stack = []  # pairs (val, current_min)\n",
    "    def push(self, x):\n",
    "        curmin = x if not self.stack else min(x, self.stack[-1][1])\n",
    "        self.stack.append((x, curmin))\n",
    "    def pop(self):\n",
    "        return self.stack.pop()[0] if self.stack else None\n",
    "    def top(self):\n",
    "        return self.stack[-1][0] if self.stack else None\n",
    "    def get_min(self):\n",
    "        return self.stack[-1][1] if self.stack else None\n",
    "\n",
    "s = MinStack()\n",
    "s.push(3); s.push(5); s.push(2); s.push(2)\n",
    "assert_test(s.get_min() == 2, \"Q12: min after pushes\")\n",
    "s.pop(); s.pop()\n",
    "assert_test(s.get_min() == 3, \"Q12: min after pops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5939b1b",
   "metadata": {},
   "source": [
    "### Q13: Implement Queue using Two Stacks\n",
    "\n",
    "Problem: Implement enqueue and dequeue using two stacks (amortized O(1)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13 Solution\n",
    "class MyQueue:\n",
    "    def __init__(self):\n",
    "        self.s1 = []\n",
    "        self.s2 = []\n",
    "    def push(self, x):\n",
    "        self.s1.append(x)\n",
    "    def pop(self):\n",
    "        if not self.s2:\n",
    "            while self.s1:\n",
    "                self.s2.append(self.s1.pop())\n",
    "        return self.s2.pop() if self.s2 else None\n",
    "    def peek(self):\n",
    "        v = self.pop()\n",
    "        if v is not None:\n",
    "            self.s2.append(v)\n",
    "        return v\n",
    "    def empty(self):\n",
    "        return not (self.s1 or self.s2)\n",
    "\n",
    "q = MyQueue()\n",
    "q.push(1); q.push(2)\n",
    "assert_test(q.pop() == 1, \"Q13: dequeue returns 1\")\n",
    "assert_test(not q.empty(), \"Q13: not empty after one pop\")\n",
    "assert_test(q.pop() == 2, \"Q13: dequeue returns 2\")\n",
    "assert_test(q.empty(), \"Q13: empty after all pops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee95fa0",
   "metadata": {},
   "source": [
    "### Q14: Evaluate Reverse Polish Notation (RPN)\n",
    "\n",
    "Problem: Evaluate arithmetic expression in RPN using a stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14 Solution\n",
    "import operator\n",
    "ops = {'+': operator.add, '-': operator.sub, '*': operator.mul, '/': lambda a,b: int(operator.truediv(a,b))}\n",
    "def eval_rpn(tokens):\n",
    "    st = []\n",
    "    for t in tokens:\n",
    "        if t in ops:\n",
    "            b = st.pop(); a = st.pop(); st.append(ops[t](a,b))\n",
    "        else:\n",
    "            st.append(int(t))\n",
    "    return st[-1]\n",
    "\n",
    "assert_test(eval_rpn([\n",
    "2\n",
    ",\n",
    "1\n",
    ",\n",
    ",\n",
    "3\n",
    ",\n",
    "]) == 9, \"Q14: (2+1)*3\")\n",
    "assert_test(eval_rpn([\n",
    "4\n",
    ",\n",
    "13\n",
    ",\n",
    "5\n",
    ",\n",
    ",\n",
    "]) == 6, \"Q14: 4 + 13/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a20b4c",
   "metadata": {},
   "source": [
    "### Q15: Balanced Parentheses\n",
    "\n",
    "Problem: Check if a string of brackets is balanced using a stack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15 Solution\n",
    "pairs = {')':'(', ']':'[', '}':'{'}\n",
    "def is_balanced(s):\n",
    "    st = []\n",
    "    for ch in s:\n",
    "        if ch in '([{': st.append(ch)\n",
    "        elif ch in pairs:\n",
    "            if not st or st.pop() != pairs[ch]: return False\n",
    "    return not st\n",
    "\n",
    "assert_test(is_balanced('()[]{}'), \"Q15: mixed balanced\")\n",
    "assert_test(not is_balanced('(]'), \"Q15: not balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87919c04",
   "metadata": {},
   "source": [
    "### Q16: Binary Search (Iterative)\n",
    "\n",
    "Problem: Implement classic binary search on sorted list, returning index or -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16 Solution\n",
    "def binary_search(a, target):\n",
    "    lo, hi = 0, len(a)-1\n",
    "    while lo <= hi:\n",
    "        mid = (lo+hi)//2\n",
    "        if a[mid] == target: return mid\n",
    "        if a[mid] < target: lo = mid+1\n",
    "        else: hi = mid-1\n",
    "    return -1\n",
    "\n",
    "assert_test(binary_search([1,2,3,4,5],3) == 2, \"Q16: found 3 at index 2\")\n",
    "assert_test(binary_search([], 1) == -1, \"Q16: empty list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f450294",
   "metadata": {},
   "source": [
    "### Q17: Merge Two Sorted Linked Lists\n",
    "\n",
    "Problem: Merge two sorted singly linked lists and return head of merged list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b287bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17 Solution\n",
    "def merge_two_lists(l1, l2):\n",
    "    dummy = Node(0); tail = dummy\n",
    "    while l1 and l2:\n",
    "        if l1.val < l2.val:\n",
    "            tail.next = l1; l1 = l1.next\n",
    "        else:\n",
    "            tail.next = l2; l2 = l2.next\n",
    "        tail = tail.next\n",
    "    tail.next = l1 or l2\n",
    "    return dummy.next\n",
    "\n",
    "a = list_from_vals([1,3,5])\n",
    "b = list_from_vals([2,4])\n",
    "m = merge_two_lists(a,b)\n",
    "assert_test(vals_from_list(m) == [1,2,3,4,5], \"Q17: merge sorted lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed308d",
   "metadata": {},
   "source": [
    "### Q18: Detect Cycle in Linked List (Floyd's Tortoise and Hare)\n",
    "\n",
    "Problem: Return True if a singly linked list has a cycle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1290a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Q18: detect cycle\n",
      "✓ Q18: no cycle\n"
     ]
    }
   ],
   "source": [
    "# Q18 Solution\n",
    "def has_cycle(head):\n",
    "    slow = fast = head\n",
    "    while fast and fast.next:\n",
    "        slow = slow.next\n",
    "        fast = fast.next.next\n",
    "        if slow is fast: return True\n",
    "    return False\n",
    "\n",
    "# build a cyclic list for test\n",
    "c = list_from_vals([1,2,3])\n",
    "tail = c; \n",
    "while tail.next: tail = tail.next\n",
    "tail.next = c.next  # create cycle\n",
    "assert_test(has_cycle(c) is True, \"Q18: detect cycle\")\n",
    "# acyclic list\n",
    "d = list_from_vals([1,2,3,4])\n",
    "assert_test(has_cycle(d) is False, \"Q18: no cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bebb45",
   "metadata": {},
   "source": [
    "### Q19: Iterative Inorder Traversal of Binary Tree\n",
    "\n",
    "Problem: Return inorder traversal using an explicit stack (no recursion).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f6c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q19 Solution\n",
    "class BTNode:\n",
    "    def __init__(self, v, l=None, r=None):\n",
    "        self.val = v; self.left = l; self.right = r\n",
    "\n",
    "def inorder_iter(root):\n",
    "    res = []; stack = []; cur = root\n",
    "    while cur or stack:\n",
    "        while cur:\n",
    "            stack.append(cur); cur = cur.left\n",
    "        cur = stack.pop(); res.append(cur.val); cur = cur.right\n",
    "    return res\n",
    "\n",
    "root = BTNode(1, BTNode(2), BTNode(3))\n",
    "assert_test(inorder_iter(root) == [2,1,3], \"Q19: inorder traversal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd67e4",
   "metadata": {},
   "source": [
    "### Q20: Topological Sort (Kahn's Algorithm)\n",
    "\n",
    "Problem: Given directed acyclic graph adjacency list, return one topological ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q20 Solution\n",
    "from collections import deque\n",
    "def topo_sort(adj):\n",
    "    indeg = {u:0 for u in adj}\n",
    "    for u in adj:\n",
    "        for v in adj[u]: indeg[v] = indeg.get(v,0)+1\n",
    "    q = deque([u for u in indeg if indeg[u]==0])\n",
    "    res = []\n",
    "    while q:\n",
    "        u = q.popleft(); res.append(u)\n",
    "        for v in adj.get(u,[]):\n",
    "            indeg[v] -= 1\n",
    "            if indeg[v]==0: q.append(v)\n",
    "    return res if len(res)==len(indeg) else []\n",
    "\n",
    "adj = {'a':['b','c'],'b':['d'],'c':['d'],'d':[]}\n",
    "order = topo_sort(adj)\n",
    "assert_test(set(order) == set(['a','b','c','d']), \"Q20: topo sort covers nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d43bd",
   "metadata": {},
   "source": [
    "### Q21: Trie (Prefix Tree) - insert and search\n",
    "\n",
    "Problem: Implement a basic Trie supporting insert and search (full word).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q21 Solution\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.is_word = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self): self.root = TrieNode()\n",
    "    def insert(self, word):\n",
    "        cur = self.root\n",
    "        for ch in word: cur = cur.children.setdefault(ch, TrieNode())\n",
    "        cur.is_word = True\n",
    "    def search(self, word):\n",
    "        cur = self.root\n",
    "        for ch in word:\n",
    "            if ch not in cur.children: return False\n",
    "            cur = cur.children[ch]\n",
    "        return cur.is_word\n",
    "\n",
    "t = Trie(); t.insert('cat'); t.insert('car')\n",
    "assert_test(t.search('cat') and not t.search('ca') and t.search('car'), \"Q21: trie insert/search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbecf141",
   "metadata": {},
   "source": [
    "### Q22: Longest Consecutive Sequence in Array\n",
    "\n",
    "Problem: Find length of longest consecutive elements sequence using a set (O(n)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f73c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q22 Solution\n",
    "def longest_consecutive(nums):\n",
    "    s = set(nums); best = 0\n",
    "    for x in s:\n",
    "        if x-1 not in s:\n",
    "            cur = x; cnt = 1\n",
    "            while cur+1 in s: cur += 1; cnt += 1\n",
    "            best = max(best, cnt)\n",
    "    return best\n",
    "\n",
    "assert_test(longest_consecutive([100,4,200,1,3,2]) == 4, \"Q22: 1-4 sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40701d92",
   "metadata": {},
   "source": [
    "### Q23: Disjoint Set (Union-Find) with Path Compression\n",
    "\n",
    "Problem: Implement union and find with path compression and union by rank.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q23 Solution\n",
    "class DSU:\n",
    "    def __init__(self, n):\n",
    "        self.parent = list(range(n)); self.rank = [0]*n\n",
    "    def find(self, x):\n",
    "        if self.parent[x]!=x: self.parent[x] = self.find(self.parent[x])\n",
    "        return self.parent[x]\n",
    "    def union(self, a,b):\n",
    "        ra, rb = self.find(a), self.find(b)\n",
    "        if ra==rb: return False\n",
    "        if self.rank[ra] < self.rank[rb]: self.parent[ra]=rb\n",
    "        elif self.rank[rb] < self.rank[ra]: self.parent[rb]=ra\n",
    "        else: self.parent[rb]=ra; self.rank[ra]+=1\n",
    "        return True\n",
    "\n",
    "d = DSU(5)\n",
    "d.union(0,1); d.union(1,2)\n",
    "assert_test(d.find(2) == d.find(0), \"Q23: union/find\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea709d5",
   "metadata": {},
   "source": [
    "### Q24: Median from Data Stream (Two Heaps)\n",
    "\n",
    "Problem: Maintain median while streaming numbers using two heaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q24 Solution\n",
    "import heapq\n",
    "class MedianFinder:\n",
    "    def __init__(self):\n",
    "        self.lo = []  # maxheap via negatives\n",
    "        self.hi = []  # minheap\n",
    "    def add(self, x):\n",
    "        if not self.lo or x <= -self.lo[0]: heapq.heappush(self.lo, -x)\n",
    "        else: heapq.heappush(self.hi, x)\n",
    "        if len(self.lo) > len(self.hi)+1: heapq.heappush(self.hi, -heapq.heappop(self.lo))\n",
    "        if len(self.hi) > len(self.lo): heapq.heappush(self.lo, -heapq.heappop(self.hi))\n",
    "    def median(self):\n",
    "        if not self.lo: return None\n",
    "        if len(self.lo) > len(self.hi): return -self.lo[0]\n",
    "        return (-self.lo[0] + self.hi[0]) / 2\n",
    "\n",
    "m = MedianFinder(); [m.add(x) for x in [1,2,3]]\n",
    "assert_test(m.median() == 2, \"Q24: median of 1,2,3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b9086",
   "metadata": {},
   "source": [
    "### Q25: Circular Buffer (Fixed Capacity)\n",
    "\n",
    "Problem: Implement a simple ring buffer supporting append and get all elements in order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0124fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q25 Solution\n",
    "class CircularBuffer:\n",
    "    def __init__(self, k):\n",
    "        self.buf = [None]*k; self.k=k; self.start=0; self.size=0\n",
    "    def append(self, x):\n",
    "        if self.size < self.k:\n",
    "            self.buf[(self.start + self.size) % self.k] = x; self.size += 1\n",
    "        else:\n",
    "            self.buf[self.start] = x; self.start = (self.start+1)%self.k\n",
    "    def to_list(self):\n",
    "        return [self.buf[(self.start+i)%self.k] for i in range(self.size)]\n",
    "\n",
    "cb = CircularBuffer(3)\n",
    "cb.append(1); cb.append(2); cb.append(3)\n",
    "assert_test(cb.to_list() == [1,2,3], \"Q25: buffer full\")\n",
    "cb.append(4)\n",
    "assert_test(cb.to_list() == [2,3,4], \"Q25: overwritten oldest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d023e7b",
   "metadata": {},
   "source": [
    "### Q26: Isomorphic Strings\n",
    "\n",
    "Problem: Determine if two strings are isomorphic (character mapping is one-to-one).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q26 Solution\n",
    "def is_isomorphic(s,t):\n",
    "    if len(s)!=len(t): return False\n",
    "    m1 = {}; m2 = {}\n",
    "    for a,b in zip(s,t):\n",
    "        if m1.get(a, b) != b or m2.get(b, a) != a: return False\n",
    "        m1[a]=b; m2[b]=a\n",
    "    return True\n",
    "\n",
    "assert_test(is_isomorphic('egg','add'), \"Q26: egg/add\")\n",
    "assert_test(not is_isomorphic('foo','bar'), \"Q26: foo/bar not iso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f6007",
   "metadata": {},
   "source": [
    "### Q27: Group Anagrams\n",
    "\n",
    "Problem: Group list of strings into anagram groups using sorted key or counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b067400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q27 Solution\n",
    "def group_anagrams(strs):\n",
    "    d = defaultdict(list)\n",
    "    for s in strs: d[''.join(sorted(s))].append(s)\n",
    "    return list(d.values())\n",
    "\n",
    "res = group_anagrams(['eat','tea','tan','ate','nat','bat'])\n",
    "assert_test(any(sorted(group)==sorted(['eat','tea','ate']) for group in res), \"Q27: anagram groups contain eat/tea/ate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df475b61",
   "metadata": {},
   "source": [
    "### Q28: Rotate Matrix 90 Degrees In-Place\n",
    "\n",
    "Problem: Rotate n x n matrix clockwise by 90 degrees in-place.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7466ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q28 Solution\n",
    "def rotate_matrix(m):\n",
    "    n = len(m)\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            m[i][j], m[j][i] = m[j][i], m[i][j]\n",
    "    for i in range(n):\n",
    "        m[i].reverse()\n",
    "\n",
    "mat = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "rotate_matrix(mat)\n",
    "assert_test(mat == [[7,4,1],[8,5,2],[9,6,3]], \"Q28: rotate 3x3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f588c",
   "metadata": {},
   "source": [
    "### Q29: Number of Islands (DFS)\n",
    "\n",
    "Problem: Count islands of '1's in a grid using DFS/BFS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8822e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q29 Solution\n",
    "def num_islands(grid):\n",
    "    if not grid: return 0\n",
    "    R, C = len(grid), len(grid[0])\n",
    "    def dfs(i,j):\n",
    "        if i<0 or j<0 or i>=R or j>=C or grid[i][j] != '1': return\n",
    "        grid[i][j] = '0'\n",
    "        for di,dj in [(1,0),(-1,0),(0,1),(0,-1)]: dfs(i+di,j+dj)\n",
    "    cnt = 0\n",
    "    for i in range(R):\n",
    "        for j in range(C):\n",
    "            if grid[i][j]=='1': cnt += 1; dfs(i,j)\n",
    "    return cnt\n",
    "\n",
    "g = [[\n",
    "1\n",
    ",\n",
    "1\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    "],[\n",
    "1\n",
    ",\n",
    "1\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    "],[\n",
    "\n",
    ",\n",
    "\n",
    ",\n",
    "1\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    "],[\n",
    "\n",
    ",\n",
    "\n",
    ",\n",
    "\n",
    ",\n",
    "1\n",
    ",\n",
    "1\n",
    "]]\n",
    "assert_test(num_islands([row[:] for row in g]) == 3, \"Q29: count islands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2472665",
   "metadata": {},
   "source": [
    "### Q30: Sparse Matrix Transpose (Dictionary of Keys)\n",
    "\n",
    "Problem: Represent sparse matrix as dict {(i,j):val} and compute transpose efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q30 Solution\n",
    "def sparse_transpose(d):\n",
    "    return {(j,i):v for (i,j),v in d.items()}\n",
    "\n",
    "s = {(0,1):5, (2,0):3}\n",
    "t = sparse_transpose(s)\n",
    "assert_test(t == {(1,0):5, (0,2):3}, \"Q30: sparse transpose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1aadb",
   "metadata": {},
   "source": [
    "# Snowflake — 15 Medium Programming Questions & Detailed Answers\n",
    "\n",
    "This document contains 15 medium-difficulty Snowflake programming questions with clear, practical solutions including SQL examples, Snowflake-specific features, and short explanations.\n",
    "\n",
    "---\n",
    "\n",
    "Q1 — Load semi-structured JSON from stage and extract nested fields\n",
    "\n",
    "Problem\n",
    "- You have newline-delimited JSON files in an internal stage. Each record has nested objects and arrays. Load into a table with extracted fields and preserve the variant.\n",
    "\n",
    "Solution\n",
    "- Create table and file format, then COPY INTO using the VARIANT column and SELECT to extract nested fields:\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE FILE FORMAT my_json_fmt TYPE = 'JSON' STRIP_OUTER_ARRAY = FALSE;\n",
    "\n",
    "CREATE OR REPLACE TABLE orders_raw (raw VARIANT);\n",
    "\n",
    "COPY INTO orders_raw\n",
    "  FROM @my_stage/path/\n",
    "  FILE_FORMAT = (FORMAT_NAME = 'my_json_fmt')\n",
    "  ON_ERROR = 'CONTINUE';\n",
    "\n",
    "-- Extract nested fields\n",
    "CREATE OR REPLACE TABLE orders AS\n",
    "SELECT\n",
    "  raw:id::STRING AS order_id,\n",
    "  raw:customer.id::STRING AS customer_id,\n",
    "  raw:customer.name::STRING AS customer_name,\n",
    "  raw:items AS items_variant,\n",
    "  raw:total::NUMBER AS total\n",
    "FROM orders_raw;\n",
    "\n",
    "-- Flatten items array\n",
    "SELECT\n",
    "  o.order_id,\n",
    "  f.value:sku::STRING AS sku,\n",
    "  f.value:qty::NUMBER AS qty\n",
    "FROM orders o,\n",
    "LATERAL FLATTEN(input => o.items_variant) f;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Use a VARIANT column to store raw JSON, then type-cast paths using the colon syntax. `LATERAL FLATTEN` expands arrays. Keep raw variant for auditing.\n",
    "\n",
    "---\n",
    "\n",
    "Q2 — Implement slowly changing dimension (SCD Type 2) using MERGE\n",
    "\n",
    "Problem\n",
    "- Maintain `dim_customer` as SCD Type 2 with effective start/end timestamps when loading a changed records file.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "-- staging_customer has incoming snapshot with natural_key and attributes\n",
    "MERGE INTO dim_customer T\n",
    "USING (\n",
    "  SELECT *, CURRENT_TIMESTAMP() AS load_ts FROM staging_customer\n",
    ") S\n",
    "ON T.natural_key = S.natural_key AND T.end_ts IS NULL\n",
    "WHEN MATCHED AND (\n",
    "     (T.attr1 IS DISTINCT FROM S.attr1) OR\n",
    "     (T.attr2 IS DISTINCT FROM S.attr2)\n",
    "  ) THEN\n",
    "  UPDATE SET end_ts = S.load_ts\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (natural_key, attr1, attr2, start_ts, end_ts)\n",
    "  VALUES (S.natural_key, S.attr1, S.attr2, S.load_ts, NULL);\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Use `MERGE` to close existing current rows by setting `end_ts`. Then insert new current rows. `IS DISTINCT FROM` handles NULL-aware comparisons.\n",
    "\n",
    "---\n",
    "\n",
    "Q3 — Stream + Task pattern: incremental ingest from staged files\n",
    "\n",
    "Problem\n",
    "- Use Snowflake Streams and Tasks to apply new staged CSV files (COPY INTO staging table) into a target table incrementally.\n",
    "\n",
    "Solution\n",
    "\n",
    "1. Create a staging table and load raw files with COPY INTO. Create a stream on staging\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE TABLE raw_events (payload VARIANT, src_file STRING, load_ts TIMESTAMP);\n",
    "CREATE OR REPLACE STREAM raw_events_stream ON TABLE raw_events;\n",
    "\n",
    "-- task that runs COPY into raw_events periodically (or triggered externally)\n",
    "CREATE OR REPLACE TASK task_load_raw\n",
    "  WAREHOUSE = my_wh\n",
    "  SCHEDULE = 'USING CRON 0 * * * * UTC'\n",
    "AS\n",
    "  COPY INTO raw_events FROM @my_stage/ FILE_FORMAT = (TYPE = 'CSV');\n",
    "\n",
    "-- Task that processes the stream into curated table\n",
    "CREATE OR REPLACE TASK task_process_stream\n",
    "  WAREHOUSE = my_wh\n",
    "  AFTER task_load_raw\n",
    "AS\n",
    "  INSERT INTO events SELECT payload:col1::STRING, payload:col2::NUMBER FROM raw_events_stream WHERE METADATA$ISROWDELETED = FALSE;\n",
    "\n",
    "-- enable tasks\n",
    "ALTER TASK task_load_raw RESUME;\n",
    "ALTER TASK task_process_stream RESUME;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Streams capture DML changes on the staging table; Tasks run scheduled pipelines. Use `METADATA$ISROWDELETED` to detect inserts vs deletes (if needed).\n",
    "\n",
    "---\n",
    "\n",
    "Q4 — Efficiently retrieve top-N per group using window functions\n",
    "\n",
    "Problem\n",
    "- Return top 3 orders by amount per customer from `orders` table.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "SELECT order_id, customer_id, total\n",
    "FROM (\n",
    "  SELECT order_id, customer_id, total,\n",
    "         ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY total DESC) AS rn\n",
    "  FROM orders\n",
    ")\n",
    "WHERE rn <= 3;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Use `ROW_NUMBER()` partitioned by customer and order by total descending. This pattern is efficient and idiomatic.\n",
    "\n",
    "---\n",
    "\n",
    "Q5 — Querying semi-structured data with conditional logic\n",
    "\n",
    "Problem\n",
    "- JSON `events` column has variable fields. Compute `event_type` with fallback logic and extract nested value when present.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "  e:id::STRING AS id,\n",
    "  COALESCE(e:type::STRING, e:meta.type::STRING, 'unknown') AS event_type,\n",
    "  CASE\n",
    "    WHEN e:event.payload IS NOT NULL THEN e:event.payload:data::STRING\n",
    "    ELSE NULL\n",
    "  END AS payload_data\n",
    "FROM raw_events;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Use `COALESCE` + variant path extraction. Use `CASE` to avoid runtime errors accessing absent paths.\n",
    "\n",
    "---\n",
    "\n",
    "Q6 — Time travel and cloning for safe data repair\n",
    "\n",
    "Problem\n",
    "- Accidentally deleted rows; restore state from time-travel to a new table for comparison and recovery.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "-- create clone from 1 hour ago\n",
    "CREATE TABLE orders_restore AS\n",
    "  SELECT * FROM orders AT (TIMESTAMP => DATEADD(hour, -1, CURRENT_TIMESTAMP()));\n",
    "\n",
    "-- compare or merge back missing rows\n",
    "MERGE INTO orders T\n",
    "USING orders_restore S\n",
    "ON T.order_id = S.order_id\n",
    "WHEN NOT MATCHED THEN INSERT *;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Time travel allows querying past data; cloning into a new table is zero-copy and fast. Use `MERGE` to recover missing rows.\n",
    "\n",
    "---\n",
    "\n",
    "Q7 — Implement a stored procedure in Snowflake using Snowpark Python to deduplicate and write results\n",
    "\n",
    "Problem\n",
    "- Use Snowpark Python procedure to deduplicate a table by natural key and write the deduped result into a target table.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE PROCEDURE dedupe_table(src_table STRING, dst_table STRING)\n",
    "  RETURNS STRING\n",
    "  LANGUAGE PYTHON\n",
    "  RUNTIME_VERSION = '3.11'\n",
    "  PACKAGES = ('snowflake-snowpark-python')\n",
    "AS\n",
    "$$\n",
    "def run(session, src_table, dst_table):\n",
    "    df = session.table(src_table)\n",
    "    # keep latest by event_ts\n",
    "    windowed = df.with_column('rn', F.row_number().over(F.Window.partition_by('natural_key').order_by(F.col('event_ts').desc())))\n",
    "    deduped = windowed.filter(F.col('rn') == 1).drop('rn')\n",
    "    deduped.write.save_as_table(dst_table, mode='overwrite')\n",
    "    return 'OK'\n",
    "$$;\n",
    "\n",
    "CALL dedupe_table('raw_src', 'curated_dst');\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Snowpark Python lets you express complex logic with DataFrame APIs server-side. Use window functions and save result to a table.\n",
    "\n",
    "---\n",
    "\n",
    "Q8 — Optimize large table joins: clustering keys and pruning\n",
    "\n",
    "Problem\n",
    "- Joining a very large fact table to dimension filtered by date range is slow. Suggest improvements.\n",
    "\n",
    "Solution\n",
    "\n",
    "Guidance:\n",
    "- Use proper clustering on the fact table (e.g., `CLUSTER BY (event_date)`) to improve pruning.\n",
    "- Ensure filters are on clustered columns. Use micro-partition pruning (verified via `QUERY_HISTORY`/`QUERY_PROFILE`).\n",
    "- Consider using a materialized view for frequently-run filtered aggregation.\n",
    "\n",
    "Example:\n",
    "\n",
    "```sql\n",
    "ALTER TABLE fact_events CLUSTER BY (event_date);\n",
    "\n",
    "CREATE MATERIALIZED VIEW mv_daily AS\n",
    "SELECT event_date, COUNT(*) AS cnt FROM fact_events GROUP BY event_date;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Clustering improves physical pruning; materialized views precompute aggregates.\n",
    "\n",
    "---\n",
    "\n",
    "Q9 — Use `FLATTEN` + windowing to compute metrics across nested arrays\n",
    "\n",
    "Problem\n",
    "- Each `session` record contains an array of `actions`. Compute total actions and top action per session.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "SELECT s.session_id,\n",
    "       COUNT(a.value) AS total_actions,\n",
    "       ARRAY_AGG(a.value ORDER BY a.value_count DESC)[0] AS top_action\n",
    "FROM (\n",
    "  SELECT session_id, f.value AS action\n",
    "  FROM sessions,\n",
    "       LATERAL FLATTEN(input => sessions.actions) f\n",
    ") a\n",
    "GROUP BY s.session_id;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Flatten then aggregate. For more complex top-K use `ROW_NUMBER()` over partition.\n",
    "\n",
    "---\n",
    "\n",
    "Q10 — COPY performance tuning for bulk CSV loads\n",
    "\n",
    "Problem\n",
    "- Loading multi-GB CSV files to Snowflake is slow. What settings and patterns improve speed?\n",
    "\n",
    "Solution\n",
    "\n",
    "Recommendations:\n",
    "- Compress files (gzip) before staging.\n",
    "- Increase `MAX_CONCURRENCY_LEVEL` and use a larger warehouse size for COPY.\n",
    "- Use `PURGE = TRUE` only after successful loads to avoid repeated processing.\n",
    "- Use consistent `FILE_FORMAT` settings (e.g., `SKIP_HEADER`, `FIELD_OPTIONALLY_ENCLOSED_BY`).\n",
    "\n",
    "Example COPY:\n",
    "\n",
    "```sql\n",
    "COPY INTO my_table\n",
    "FROM @my_stage/bulk/\n",
    "FILE_FORMAT = (type='CSV' compression='GZIP' field_delimiter=',' skip_header=1)\n",
    "ON_ERROR='ABORT_STATEMENT'\n",
    "MAX_CONCURRENCY_LEVEL = 8;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Compression reduces network IO. Larger warehouses and parallelism speed ingestion.\n",
    "\n",
    "---\n",
    "\n",
    "Q11 — Implement multi-table atomic update with transactions\n",
    "\n",
    "Problem\n",
    "- Update multiple related tables atomically (if any update fails, rollback all changes).\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "BEGIN TRANSACTION;\n",
    "  UPDATE acct_balances SET balance = balance - 100 WHERE acct_id = 1;\n",
    "  UPDATE acct_balances SET balance = balance + 100 WHERE acct_id = 2;\n",
    "  INSERT INTO transfers (from_acct, to_acct, amount, ts) VALUES (1,2,100,CURRENT_TIMESTAMP());\n",
    "COMMIT;\n",
    "\n",
    "-- In case of error, use ROLLBACK;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Snowflake supports multi-statement transactions; use `BEGIN`/`COMMIT` to ensure atomicity.\n",
    "\n",
    "---\n",
    "\n",
    "Q12 — Use `QUALIFY` to simplify filtering on analytic results\n",
    "\n",
    "Problem\n",
    "- Filter rows by the output of a window function (e.g., top 1 per group) without subquery nesting.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "SELECT order_id, customer_id, total,\n",
    "       ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY total DESC) AS rn\n",
    "FROM orders\n",
    "QUALIFY rn = 1;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- `QUALIFY` lets you filter on analytic/window expressions directly, reducing subquery complexity.\n",
    "\n",
    "---\n",
    "\n",
    "Q13 — Use `MERGE` to implement upsert with delete semantics (synchronization)\n",
    "\n",
    "Problem\n",
    "- Synchronize target table to match source: insert new, update changed, and delete target rows not present in source.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "MERGE INTO target T\n",
    "USING source S\n",
    "ON T.key = S.key\n",
    "WHEN MATCHED THEN UPDATE SET T.col1 = S.col1, T.col2 = S.col2\n",
    "WHEN NOT MATCHED THEN INSERT (key, col1, col2) VALUES (S.key, S.col1, S.col2)\n",
    "WHEN NOT MATCHED BY SOURCE AND T.update_source = 'external' THEN DELETE;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- `MERGE` supports `WHEN NOT MATCHED BY SOURCE` to delete rows that no longer exist upstream; use carefully to avoid accidental data loss.\n",
    "\n",
    "---\n",
    "\n",
    "Q14 — Implement GDPR-style soft deletion using masking + time ranges\n",
    "\n",
    "Problem\n",
    "- Support soft-deletion for PII data and automatically mask values for deleted users while retaining analytics.\n",
    "\n",
    "Solution\n",
    "\n",
    "Approach:\n",
    "- Add `deleted_at` timestamp column. Use conditional masking in views: if `deleted_at` IS NOT NULL then mask PII columns using `HASH()` or `NULL`.\n",
    "\n",
    "```sql\n",
    "CREATE OR REPLACE VIEW customer_view AS\n",
    "SELECT id,\n",
    "       CASE WHEN deleted_at IS NULL THEN email ELSE NULL END AS email,\n",
    "       CASE WHEN deleted_at IS NULL THEN ssn ELSE 'REDACTED' END AS ssn,\n",
    "       deleted_at\n",
    "FROM customer;\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Views provide controlled access—masking PII while retaining row-level metrics.\n",
    "\n",
    "---\n",
    "\n",
    "Q15 — Use materialized view to accelerate frequent aggregation with freshness constraints\n",
    "\n",
    "Problem\n",
    "- A dashboard queries daily aggregates frequently; reduce latency while keeping results near-real-time.\n",
    "\n",
    "Solution\n",
    "\n",
    "```sql\n",
    "CREATE MATERIALIZED VIEW mv_daily_sales\n",
    "CLUSTER BY (sale_date)\n",
    "AS\n",
    "SELECT sale_date, SUM(amount) AS total_sales, COUNT(*) AS tx_count\n",
    "FROM sales\n",
    "GROUP BY sale_date;\n",
    "\n",
    "-- Refresh occurs automatically; monitor via ACCOUNT_USAGE.MATERIALIZED_VIEWS\n",
    "```\n",
    "\n",
    "Explanation\n",
    "- Materialized views precompute aggregates; they trade storage for query latency. Monitor maintenance cost and invalidation frequency.\n",
    "\n",
    "---\n",
    "\n",
    "File created: `snowflake_medium_questions.md`\n",
    "\n",
    "If you want, I can also:\n",
    "- Convert this to a notebook cell, or\n",
    "- Attempt syntactic validation of these SQL snippets if you provide Snowflake credentials.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
